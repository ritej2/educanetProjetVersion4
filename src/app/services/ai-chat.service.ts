/**
 * PURPOSE: Controls the AI Assistant (Chatbot).
 * CONTENT: Sends messages to Ollama, manages system prompts (educational/nutrition focus), and handles streaming responses.
 */
import { HttpClient } from '@angular/common/http';
import { Injectable, NgZone } from '@angular/core';
import { Observable } from 'rxjs';
import { environment } from '../../environments/environment';
import { AuthService } from './auth.service';
import { ContextService, ChildProfile } from './context.service';
import { HomeworkService, Homework } from './homework.service';

export interface ChatMessage {
    text: string;
    sender: 'user' | 'ai';
    timestamp: Date;
}

@Injectable({
    providedIn: 'root'
})
export class AiChatService {

    private apiUrl = environment.OLLAMA_API_URL;
    private homeworkContext: any = null;

    // System prompt to constrain the AI to educational and nutrition topics
    // System prompt pour l'IA adapt√©e aux parents tunisiens
    private readonly SYSTEM_PROMPT = `Tu es un assistant parental virtuel sp√©cialis√© en √âDUCATION et NUTRITION, destin√© aux parents en Tunisie.
Ton objectif est d'aider les parents avec des conseils pratiques, bienveillants et personnalis√©s, en tenant compte du contexte tunisien.

DOMAINES AUTORIS√âS :
1. √âDUCATION :
   - Suivi scolaire via la plateforme **Rafi9ni** : notes, exercices, documents p√©dagogiques, devoirs et activit√©s √©ducatives.
   - Suivi de l'apprentissage et du comportement de l'enfant via **9isati**.
2. NUTRITION :
   - Recettes et conseils adapt√©s aux enfants en Tunisie.
   - **R√âF√âRENCE PRODUITS** : Utilise les produits de la marque **D√©lice** (lait, yaourts, produits laitiers, jus) comme r√©f√©rence principale pour tes conseils nutritionnels et tes id√©es de go√ªters ou repas.

R√àGLES CRITIQUES :
1. ANALYSE INITIALE : Si des donn√©es d'analyse (JSON) sont disponibles, commence par r√©sumer les points forts et faibles.
2. DOCUMENTS : Tu ne peux proposer QUE les documents list√©s dans "RESSOURCES P√âDAGOGIQUES R√âELLES". 
3. INTERDICTION : Ne jamais inventer de titres de documents. Si la liste est vide ou si aucun document ne correspond √† la mati√®re demand√©e, dis explicitement que tu n'en as pas pour le moment.
4. √âVEIL SCIENTIFIQUE : Note que ce domaine couvre la science, la physique, la chimie et la biologie.
5. LANGUE : Tu peux comprendre et r√©pondre en **fran√ßais** ou en **arabe** (arabe litt√©raire ou derja tunisienne), selon la pr√©f√©rence du parent. Garde toujours un ton clair et bienveillant.`;

    private conversationHistory: Array<{ role: string; content: string }> = [
        { role: 'system', content: this.SYSTEM_PROMPT }
    ];

    constructor(
        private http: HttpClient,
        private authService: AuthService,
        private contextService: ContextService,
        private homeworkService: HomeworkService,
        private ngZone: NgZone
    ) {
        this.authService.currentUser$.subscribe(user => {
            if (user) {
                console.log('AiChatService: Utilisateur connect√©, chargement du profil...', user.id);
                this.contextService.loadProfileForUser(user.id);
                this.homeworkService.loadLibrary(user.id);
                this.updateSystemPromptWithProfile();
            } else {
                this.homeworkService.clearLibrary();
                this.clearHistory();
            }
        });

        // 1. React to Profile Changes -> Trigger Search for each child if needed
        this.contextService.childProfile$.subscribe(profiles => {
            console.log('AiChatService: Changement de profils d√©tect√©:', profiles?.length || 0);

            // On d√©clenche la recherche pour le dernier profil mis √† jour (le dernier de la liste)
            if (profiles && profiles.length > 0) {
                const latestProfile = this.contextService.getProfile();
                if (latestProfile) {
                    this.homeworkService.performSearch(latestProfile);
                }
            }

            this.updateSystemPromptWithProfile();
        });

        // 2. React to Documents Found -> Update Prompt
        this.homeworkService.recommendedDocuments$.subscribe((docs: Homework[]) => {
            console.log('AiChatService: Documents mis √† jour:', docs.length);
            this.homeworkContext = docs;
            this.updateSystemPromptWithProfile();
        });
    }

    setHomeworkContext(homeworkData: any): void {
        // Legacy support if needed, but now we use subscription
        this.homeworkContext = homeworkData;
        this.updateSystemPromptWithProfile();
    }

    private getSystemPromptWithProfile(): string {
        let fullPrompt = this.SYSTEM_PROMPT;
        const allProfiles = this.contextService.getAllProfiles();

        if (allProfiles && allProfiles.length > 0) {
            fullPrompt += `
            
            ${this.contextService.getAnalysisJSON()}

R√âSUM√â DES ENFANTS ACTUELS :`;

            allProfiles.forEach((p, index) => {
                const child = this.contextService.formatChildSummary(p);
                fullPrompt += `
Enfant ${index + 1} : ${child.q_nom || 'Sans nom'}
- Niveau : ${child.niveauScolaire}
- Mati√®res √† renforcer : ${child.matieresEnDifficulte.join(', ')}
- Observations : ${child.pointsAAmeliorer}`;
            });
        }

        if (this.homeworkContext && Array.isArray(this.homeworkContext) && this.homeworkContext.length > 0) {
            const docs = this.homeworkContext.map((d: any) => ({
                titre: d.title,
                matiere: d.subject,
                fichiers: d.files.map((f: any) => f.nom)
            }));

            fullPrompt += `

üìö RESSOURCES P√âDAGOGIQUES R√âELLES (Actuellement dans la Biblioth√®que du parent) :
${JSON.stringify(docs, null, 2)}

INSTRUCTION CRITIQUE : 
1. Si cette liste contient des documents pertinents pour la mati√®re demand√©e, recommande-les en citant le TITRE EXACT.
2. Explique que ces documents sont d√©j√† pr√™ts dans l'onglet "Biblioth√®que".
3. SI LA LISTE CI-DESSUS EST VIDE OU NE CONTIENT PAS LA MATI√àRE DEMAND√âE : Explique que tu n'as pas encore de documents sp√©cifiques pour cette mati√®re dans sa biblioth√®que personnelle, et propose des conseils g√©n√©raux en attendant.
4. NE JAMAIS INVENTER DE DOCUMENT.`;
        } else {
            fullPrompt += `\n\nNOTE : Aucune ressource sp√©cifique n'est encore charg√©e dans la biblioth√®que. Propose des conseils g√©n√©raux et invite le parent √† v√©rifier le questionnaire.`;
        }

        fullPrompt += `\n\nR√©ponds de mani√®re concise et guide toujours le parent vers les outils de la plateforme Rafi9ni.`;

        return fullPrompt;
    }

    private updateSystemPromptWithProfile(): void {
        const fullPrompt = this.getSystemPromptWithProfile();
        console.log('AiChatService: Syst√®me Prompt mis √† jour avec le contexte:', fullPrompt);

        // Ensure the system prompt is always at the beginning of the history
        if (this.conversationHistory.length > 0 && this.conversationHistory[0].role === 'system') {
            this.conversationHistory[0].content = fullPrompt;
        } else {
            this.conversationHistory.unshift({ role: 'system', content: fullPrompt });
        }
    }

    sendMessageStream(userMessage: string): Observable<string> {
        // The system prompt is already managed by updateSystemPromptWithProfile() 
        // which is called when the profile or homework context changes.
        // We just need to ensure it's there.
        this.updateSystemPromptWithProfile();

        // Add user message to conversation history
        this.conversationHistory.push({
            role: 'user',
            content: userMessage
        });

        return new Observable(observer => {
            const body = {
                model: 'llama3.2',
                messages: this.conversationHistory,
                stream: true,
                options: {
                    temperature: 0.7,
                    num_ctx: 4096
                }
            };

            console.log('AiChatService: Envoi requ√™te √† Ollama (llama3.2)...');
            console.dir(body.messages);

            fetch(this.apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(body)
            })
                .then(async response => {
                    console.log('AiChatService: R√©ponse re√ßue de Ollama, status:', response.status);
                    if (!response.ok) {
                        const text = await response.text();
                        throw new Error(`Ollama error (${response.status}): ${text}`);
                    }

                    const reader = response.body?.getReader();
                    const decoder = new TextDecoder();
                    let fullResponse = '';
                    let buffer = '';

                    const readChunk = (): void => {
                        reader?.read().then(({ done, value }) => {
                            if (done) {
                                // Process any remaining content in buffer
                                if (buffer.trim()) {
                                    this.processJsonLines(buffer, (content) => {
                                        fullResponse += content;
                                        this.ngZone.run(() => observer.next(content));
                                    });
                                }

                                // Add AI response to conversation history
                                this.conversationHistory.push({
                                    role: 'assistant',
                                    content: fullResponse
                                });
                                console.log('AiChatService: Flux termin√©. Appel √† observer.complete()');
                                this.ngZone.run(() => observer.complete());
                                return;
                            }

                            const chunk = decoder.decode(value, { stream: true });
                            buffer += chunk;

                            const lastNewlineIndex = buffer.lastIndexOf('\n');
                            if (lastNewlineIndex !== -1) {
                                const linesToProcess = buffer.substring(0, lastNewlineIndex);
                                buffer = buffer.substring(lastNewlineIndex + 1);

                                this.processJsonLines(linesToProcess, (content) => {
                                    fullResponse += content;
                                    this.ngZone.run(() => observer.next(content));
                                });
                            }

                            readChunk();
                        }).catch(error => {
                            this.ngZone.run(() => observer.error(error));
                        });
                    };

                    readChunk();
                })
                .catch(error => {
                    this.ngZone.run(() => observer.error(error));
                });
        });
    }

    private processJsonLines(text: string, onContent: (content: string) => void): void {
        const lines = text.split('\n').filter(line => line.trim() !== '');
        for (const line of lines) {
            try {
                const json = JSON.parse(line);
                let content = '';

                // standard chat content
                if (json.message?.content) {
                    content += json.message.content;
                }

                // reasoning/thought content if model supports it
                if (json.message?.thought) {
                    content += `[Pens√©e : ${json.message.thought}] `;
                }

                if (content) {
                    onContent(content);
                }
            } catch (e) {
                // Skip invalid JSON lines (might be partial)
            }
        }
    }

    clearHistory(): void {
        this.conversationHistory = [
            { role: 'system', content: this.getSystemPromptWithProfile() }
        ];
    }

    setHistory(messages: Array<{ role: string; content: string }>): void {
        this.conversationHistory = [
            { role: 'system', content: this.getSystemPromptWithProfile() },
            ...messages
        ];
    }
}
